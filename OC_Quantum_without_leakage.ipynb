{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daddba7-bf83-46c5-a7eb-68779182aa21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a19a508-7b9d-47dc-b09e-26790cc42ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entropy by Group (vNE; normalized to 'All' if present) ===\n",
      "  Group    vNE  vNE_norm\n",
      "Panel_E 1.8892    2.4042\n",
      "Panel_D 1.2590    1.6022\n",
      "Panel_B 1.0712    1.3632\n",
      "    All 0.7858    1.0000\n",
      "Panel_C 0.0045    0.0058\n",
      "Panel_A 0.0004    0.0006\n",
      "\n",
      "=== Pairwise Synergy (bootstrapped) ===\n",
      "    G_A     G_B    S_A    S_B  S_AuB  S_ratio  S_boot_mean  CI_low  CI_high\n",
      "Panel_B Panel_E 1.0712 1.8892 1.9131   0.6462       0.6576  0.5803   0.7724\n",
      "Panel_D Panel_E 1.2590 1.8892 1.8902   0.6004       0.5988  0.5581   0.6313\n",
      "Panel_B Panel_D 1.0712 1.2590 1.2376   0.5311       0.5226  0.4002   0.6233\n",
      "\n",
      "=== AUC Comparison (5-fold CV) ===\n",
      "          Group  AUC_GBM_5CV  AUC_MLP_5CV  Num_Features\n",
      "            All       0.7068       0.6316            36\n",
      "    All∪Panel_C       0.7068       0.6316            36\n",
      "        Panel_B       0.7067       0.6659             7\n",
      "Panel_A∪Panel_C       0.7053       0.5403            14\n",
      "        Panel_C       0.6881       0.5482             8\n",
      "        Panel_A       0.6735       0.5305             6\n",
      "        Panel_E       0.6573       0.4552             8\n",
      "        Panel_D       0.4846       0.4598             7\n",
      "\n",
      "=== Permutation Importance (Panel A ∪ C) top 25 ===\n",
      "               feature  importance\n",
      "      panelc_ca_125_fc    0.041190\n",
      "    panela_ca_125_u_ml    0.023868\n",
      "  panelc_mesothelin_fc    0.021414\n",
      "    panelc_spondin2_fc    0.017069\n",
      "         panelc_he4_fc    0.013924\n",
      "        panelc_slpi_fc    0.010449\n",
      "     panelc_mmp7_ng_ml    0.008425\n",
      "      panela_mif_pg_ml    0.007948\n",
      "  panelc_igfbpii_ng_ml    0.005704\n",
      "      panela_opn_pg_ml    0.004704\n",
      "     panelc_igfbpii_fc    0.004066\n",
      "   panela_igf_ii_ng_ml    0.004030\n",
      "   panela_leptin_ng_ml    0.001375\n",
      "panela_prolactin_ng_ml    0.000482\n",
      "\n",
      "=== Possible Leakage Features (keyword scan; top 50) ===\n",
      "               feature  possible_leak\n",
      "          ovar_exitage           True\n",
      "           bq_compdays           True\n",
      "         entrydays_dhq           True\n",
      "         entrydays_sqx           True\n",
      "     ovar_eligible_dhq           True\n",
      "     ovar_eligible_sqx           True\n",
      "      ovar_eligible_bq           True\n",
      "         ovar_exitstat           True\n",
      "       sample_drawdays           True\n",
      "     mortality_exitage           True\n",
      "    mortality_exitstat           True\n",
      "     ovar_eligible_dqx           True\n",
      "reconsent_outcome_days           True\n",
      "       fstcan_exitstat           True\n",
      "        fstcan_exitage           True\n",
      "       fstcan_exitdays           True\n",
      "         ovar_exitdays           True\n",
      "    build_death_cutoff           True\n",
      "    mortality_exitdays           True\n",
      "          entrydays_bq           True\n",
      "              bmi_curr          False\n",
      "              weight_f          False\n",
      "              bmi_curc          False\n",
      "                bmi_20          False\n",
      "            weight20_f          False\n",
      "            weight50_f          False\n",
      "              height_f          False\n",
      "         ca125_history          False\n",
      "     menstrs_stat_type          False\n",
      "       post_menopausal          False\n",
      "               bmi_20c          False\n",
      "                bmi_50          False\n",
      "             horm_stat          False\n",
      "            pack_years          False\n",
      "            hispanic_f          False\n",
      "              polyps_f          False\n",
      "             arthrit_f          False\n",
      "            osteopor_f          False\n",
      "            divertic_f          False\n",
      "            gallblad_f          False\n",
      "           bq_returned          False\n",
      "                bq_age          False\n",
      "                 race7          False\n",
      "                preg_f          False\n",
      "             cig_years          False\n",
      "              hyster_f          False\n",
      "            ovariesr_f          False\n",
      "              bcontr_f          False\n",
      "                horm_f          False\n",
      "     colon_comorbidity          False\n",
      "\n",
      "=== Slide-Ready Summary ===\n",
      "Best Synergy Pair  Mean Synergy           95% CI  Delta AUC (GBM): A∪C vs C  Delta AUC (GBM): All∪C vs All  AUC (GBM) All\n",
      "Panel_B + Panel_E        0.6576 [0.5803, 0.7724]                        NaN                            NaN            NaN\n",
      "              NaN           NaN              NaN                     0.0172                            0.0         0.7068\n",
      "\n",
      "Saved files in working directory:\n",
      " - entropy_by_group.csv\n",
      " - synergy_pairs.csv\n",
      " - auc_comparison.csv\n",
      " - feature_importance_A_C.csv (if A,C exist)\n",
      " - leakage_report.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Quantum-Entropy Synergy & ML Baselines\n",
    "# Data: merged_ovars_plco.csv (label: is_case 0/1)\n",
    "# Outputs: CSVs + printed slide-ready summary\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import eigh\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "DATA_PATH = r\"D:\\Lakshmi Kumari\\merged_oc_ovars.csv\"  \n",
    "LABEL_COL = \"is_case\"\n",
    "PANEL_PREFIXES = {\n",
    "    \"Panel_A\": \"panela_\",\n",
    "    \"Panel_B\": \"panelb_\",\n",
    "    \"Panel_C\": \"panelc_\",\n",
    "    \"Panel_D\": \"paneld_\",\n",
    "    \"Panel_E\": \"panele_\",\n",
    "}\n",
    "BOOTSTRAP_B = 500   # set to 1000 if you want tighter CIs and have time\n",
    "RANDOM_SEED = 7\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def vne_entropy(X: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Von Neumann entropy of covariance-derived density matrix.\"\"\"\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    # center and simple mean-impute to keep covariance defined\n",
    "    X = X - np.nanmean(X, axis=0, keepdims=True)\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    inds = np.where(np.isnan(X))\n",
    "    X[inds] = np.take(col_means, inds[1])\n",
    "    C = np.cov(X, rowvar=False)\n",
    "    tr = np.trace(C)\n",
    "    if tr <= eps:\n",
    "        return 0.0\n",
    "    rho = C / tr\n",
    "    vals = eigh(rho, UPLO='U')[0]\n",
    "    vals = vals[vals > eps]\n",
    "    return float(-(vals * np.log2(vals)).sum())\n",
    "\n",
    "def synergy_ratio(SA: float, SB: float, S_union: float, eps: float = 1e-12) -> float:\n",
    "    return S_union / (SA + SB + eps)\n",
    "\n",
    "def bootstrap_ci(values: np.ndarray, alpha: float = 0.05) -> Tuple[float, float]:\n",
    "    lo = np.quantile(values, alpha/2)\n",
    "    hi = np.quantile(values, 1 - alpha/2)\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def bootstrap_synergy(XA: np.ndarray, XB: np.ndarray, B: int = 500, seed: int = 42) -> Tuple[float, Tuple[float,float]]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = XA.shape[0]\n",
    "    s_vals = np.empty(B, dtype=float)\n",
    "    for i in range(B):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        SA = vne_entropy(XA[idx])\n",
    "        SB = vne_entropy(XB[idx])\n",
    "        S_union = vne_entropy(np.hstack([XA[idx], XB[idx]]))\n",
    "        s_vals[i] = synergy_ratio(SA, SB, S_union)\n",
    "    mean_s = float(np.mean(s_vals))\n",
    "    ci = bootstrap_ci(s_vals, alpha=0.05)\n",
    "    return mean_s, ci\n",
    "\n",
    "def prefix_groups(df: pd.DataFrame, prefixes: Dict[str, str]) -> Dict[str, List[str]]:\n",
    "    groups = {}\n",
    "    for gname, pref in prefixes.items():\n",
    "        cols = [c for c in df.columns if str(c).startswith(pref)]\n",
    "        groups[gname] = cols\n",
    "    all_cols = sorted({c for cols in groups.values() for c in cols})\n",
    "    groups[\"All\"] = all_cols\n",
    "    return groups\n",
    "\n",
    "def extract_arrays(df: pd.DataFrame, groups: Dict[str, List[str]]) -> Dict[str, np.ndarray]:\n",
    "    return {g: df[cols].to_numpy() for g, cols in groups.items() if len(cols) > 0}\n",
    "\n",
    "def entropy_by_group(group_arrays: Dict[str, np.ndarray], all_group_name: str = \"All\") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    S_all = vne_entropy(group_arrays[all_group_name]) if all_group_name in group_arrays else None\n",
    "    for g, X in group_arrays.items():\n",
    "        Sg = vne_entropy(X)\n",
    "        rows.append((g, Sg))\n",
    "    ent_df = pd.DataFrame(rows, columns=[\"Group\", \"vNE\"])\n",
    "    denom = S_all if (S_all is not None and S_all > 0) else (ent_df[\"vNE\"].max() if ent_df[\"vNE\"].max() > 0 else 1.0)\n",
    "    ent_df[\"vNE_norm\"] = ent_df[\"vNE\"] / denom\n",
    "    return ent_df.sort_values(\"vNE_norm\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def synergy_scan(group_arrays: Dict[str, np.ndarray],\n",
    "                 exclude_near_zero: bool = True,\n",
    "                 threshold: float = 0.01,\n",
    "                 B: int = 500) -> pd.DataFrame:\n",
    "    raw_ent = {g: vne_entropy(X) for g, X in group_arrays.items()}\n",
    "    valid = {g: X for g, X in group_arrays.items() if (not exclude_near_zero) or (raw_ent[g] >= threshold)}\n",
    "    rows = []\n",
    "    keys = [k for k in valid.keys() if k != \"All\"]  # avoid pairing \"All\" with everything\n",
    "    for A, Bname in combinations(keys, 2):\n",
    "        XA, XB = valid[A], valid[Bname]\n",
    "        SA, SB = raw_ent[A], raw_ent[Bname]\n",
    "        S_union = vne_entropy(np.hstack([XA, XB]))\n",
    "        Sratio = synergy_ratio(SA, SB, S_union)\n",
    "        mean_s, ci = bootstrap_synergy(XA, XB, B=B, seed=RANDOM_SEED)\n",
    "        rows.append((A, Bname, SA, SB, S_union, Sratio, mean_s, ci[0], ci[1]))\n",
    "    res = pd.DataFrame(rows, columns=[\"G_A\", \"G_B\", \"S_A\", \"S_B\", \"S_AuB\", \"S_ratio\", \"S_boot_mean\", \"CI_low\", \"CI_high\"])\n",
    "    return res.sort_values(\"S_boot_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def cv_auc_baseline(X: np.ndarray, y: np.ndarray, model: str = \"gbm\", seed: int = 7) -> float:\n",
    "    if model == \"gbm\":\n",
    "        clf = GradientBoostingClassifier(random_state=seed)\n",
    "    elif model == \"mlp\":\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
    "              solver=\"adam\",\n",
    "              learning_rate_init=1e-3,\n",
    "              alpha=1e-3,           # a bit more regularization helps converge\n",
    "              early_stopping=True,  # splits off validation fold internally\n",
    "              n_iter_no_change=15,\n",
    "              tol=1e-4,\n",
    "              max_iter=1000,\n",
    "              random_state=7)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"model must be 'gbm' or 'mlp'\")\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    auc = cross_val_score(pipe, X, y, cv=cv, scoring=\"roc_auc\").mean()\n",
    "    return float(auc)\n",
    "\n",
    "def auc_for_panels(df: pd.DataFrame, y: np.ndarray, groups: Dict[str, List[str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for g in [\"Panel_A\", \"Panel_B\", \"Panel_C\", \"Panel_D\", \"Panel_E\", \"All\"]:\n",
    "        if g in groups and len(groups[g]) > 0:\n",
    "            Xg = df[groups[g]].to_numpy()\n",
    "            auc_gbm = cv_auc_baseline(Xg, y, model=\"gbm\", seed=RANDOM_SEED)\n",
    "            auc_mlp = cv_auc_baseline(Xg, y, model=\"mlp\", seed=RANDOM_SEED)\n",
    "            rows.append((g, auc_gbm, auc_mlp, len(groups[g])))\n",
    "\n",
    "    if all(k in groups and len(groups[k]) > 0 for k in [\"Panel_A\", \"Panel_C\"]):\n",
    "        cols = groups[\"Panel_A\"] + groups[\"Panel_C\"]\n",
    "        Xac = df[cols].to_numpy()\n",
    "        rows.append((\"Panel_A∪Panel_C\",\n",
    "                     cv_auc_baseline(Xac, y, \"gbm\", RANDOM_SEED),\n",
    "                     cv_auc_baseline(Xac, y, \"mlp\", RANDOM_SEED),\n",
    "                     len(cols)))\n",
    "    if all(k in groups and len(groups[k]) > 0 for k in [\"All\", \"Panel_C\"]):\n",
    "        cols = sorted(set(groups[\"All\"] + groups[\"Panel_C\"]))\n",
    "        Xallc = df[cols].to_numpy()\n",
    "        rows.append((\"All∪Panel_C\",\n",
    "                     cv_auc_baseline(Xallc, y, \"gbm\", RANDOM_SEED),\n",
    "                     cv_auc_baseline(Xallc, y, \"mlp\", RANDOM_SEED),\n",
    "                     len(cols)))\n",
    "\n",
    "    auc_df = pd.DataFrame(rows, columns=[\"Group\", \"AUC_GBM_5CV\", \"AUC_MLP_5CV\", \"Num_Features\"])\n",
    "    return auc_df.sort_values(\"AUC_GBM_5CV\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "LEAKAGE_KEYWORDS = [\"exit\", \"death\", \"event\", \"status\", \"eligible\", \"follow\", \"survival\", \"days\"]\n",
    "\n",
    "def leakage_report(df: pd.DataFrame, label_col: str) -> pd.DataFrame:\n",
    "    cols = [c for c in df.columns if c != label_col]\n",
    "    flags = []\n",
    "    for c in cols:\n",
    "        low = str(c).lower()\n",
    "        suspicious = any(k in low for k in LEAKAGE_KEYWORDS)\n",
    "        flags.append((c, suspicious))\n",
    "    return pd.DataFrame(flags, columns=[\"feature\", \"possible_leak\"]).sort_values(\"possible_leak\", ascending=False)\n",
    "\n",
    "def permutation_importance_report(df: pd.DataFrame, y: np.ndarray, cols: List[str], seed: int = 7) -> pd.DataFrame:\n",
    "    X = df[cols].to_numpy()\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=seed)),\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "    r = permutation_importance(pipe, X, y, n_repeats=10, random_state=seed, scoring=\"roc_auc\")\n",
    "    df_imp = pd.DataFrame({\"feature\": cols, \"importance\": r.importances_mean})\n",
    "    return df_imp.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "assert LABEL_COL in df.columns, f\"Label column '{LABEL_COL}' not found.\"\n",
    "y = df[LABEL_COL].astype(int).to_numpy()\n",
    "\n",
    "# Build groups by prefix and arrays\n",
    "groups = prefix_groups(df, PANEL_PREFIXES)\n",
    "group_arrays = extract_arrays(df, groups)\n",
    "\n",
    "# 1) Entropy landscape\n",
    "entropy_df = entropy_by_group(group_arrays, all_group_name=\"All\")\n",
    "entropy_df.to_csv(\"entropy_by_group.csv\", index=False)\n",
    "print(\"\\n=== Entropy by Group (vNE; normalized to 'All' if present) ===\")\n",
    "print(entropy_df.round(4).to_string(index=False))\n",
    "\n",
    "# 2) Synergy scan with bootstrapped CI\n",
    "synergy_df = synergy_scan(group_arrays, exclude_near_zero=True, threshold=0.01, B=BOOTSTRAP_B)\n",
    "synergy_df.to_csv(\"synergy_pairs.csv\", index=False)\n",
    "print(\"\\n=== Pairwise Synergy (bootstrapped) ===\")\n",
    "print(synergy_df.round(4).head(20).to_string(index=False))\n",
    "\n",
    "# 3) AUC comparisons (GBM & MLP)\n",
    "auc_df = auc_for_panels(df, y, groups)\n",
    "auc_df.to_csv(\"auc_comparison.csv\", index=False)\n",
    "print(\"\\n=== AUC Comparison (5-fold CV) ===\")\n",
    "print(auc_df.round(4).to_string(index=False))\n",
    "\n",
    "# 4) Permutation importance for A∪C (if present)\n",
    "if all(k in groups and len(groups[k])>0 for k in [\"Panel_A\", \"Panel_C\"]):\n",
    "    ac_cols = groups[\"Panel_A\"] + groups[\"Panel_C\"]\n",
    "    imp_ac_df = permutation_importance_report(df, y, ac_cols, seed=RANDOM_SEED)\n",
    "    imp_ac_df.to_csv(\"feature_importance_A_C.csv\", index=False)\n",
    "    print(\"\\n=== Permutation Importance (Panel A ∪ C) top 25 ===\")\n",
    "    print(imp_ac_df.head(25).round(6).to_string(index=False))\n",
    "\n",
    "# 5) Leakage keyword scan\n",
    "leak_df = leakage_report(df, LABEL_COL)\n",
    "leak_df.to_csv(\"leakage_report.csv\", index=False)\n",
    "print(\"\\n=== Possible Leakage Features (keyword scan; top 50) ===\")\n",
    "print(leak_df.head(50).to_string(index=False))\n",
    "\n",
    "# 6) Slide-ready summary\n",
    "summary_rows = []\n",
    "if not synergy_df.empty:\n",
    "    top = synergy_df.iloc[0]\n",
    "    summary_rows.append({\n",
    "        \"Best Synergy Pair\": f\"{top['G_A']} + {top['G_B']}\",\n",
    "        \"Mean Synergy\": round(top[\"S_boot_mean\"], 4),\n",
    "        \"95% CI\": f\"[{round(top['CI_low'],4)}, {round(top['CI_high'],4)}]\"\n",
    "    })\n",
    "\n",
    "def _get_auc(group_name, col):\n",
    "    if group_name in set(auc_df[\"Group\"]):\n",
    "        return float(auc_df.loc[auc_df[\"Group\"]==group_name, col].iloc[0])\n",
    "    return np.nan\n",
    "\n",
    "auc_ac_gbm = _get_auc(\"Panel_A∪Panel_C\", \"AUC_GBM_5CV\")\n",
    "auc_c_gbm   = _get_auc(\"Panel_C\", \"AUC_GBM_5CV\")\n",
    "auc_all_gbm = _get_auc(\"All\", \"AUC_GBM_5CV\")\n",
    "auc_allc_gbm= _get_auc(\"All∪Panel_C\", \"AUC_GBM_5CV\")\n",
    "\n",
    "summary_rows.append({\n",
    "    \"Delta AUC (GBM): A∪C vs C\": None if np.isnan(auc_ac_gbm) or np.isnan(auc_c_gbm) else round(auc_ac_gbm - auc_c_gbm, 4),\n",
    "    \"Delta AUC (GBM): All∪C vs All\": None if np.isnan(auc_allc_gbm) or np.isnan(auc_all_gbm) else round(auc_allc_gbm - auc_all_gbm, 4),\n",
    "    \"AUC (GBM) All\": None if np.isnan(auc_all_gbm) else round(auc_all_gbm, 4)\n",
    "})\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"summary_slide_ready.csv\", index=False)\n",
    "print(\"\\n=== Slide-Ready Summary ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nSaved files in working directory:\")\n",
    "print(\" - entropy_by_group.csv\")\n",
    "print(\" - synergy_pairs.csv\")\n",
    "print(\" - auc_comparison.csv\")\n",
    "print(\" - feature_importance_A_C.csv (if A,C exist)\")\n",
    "print(\" - leakage_report.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba89f86a-1b34-414b-82bb-52b0c798fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLCO\n",
      "================================\n",
      "Analyzing PLCO dataset\n",
      "================================\n",
      "✅ Loaded PLCO: 1101 samples, 177 features, target balance = 0.11\n",
      "Loaded 1101 rows. Target distribution:\n",
      "        count\n",
      "target       \n",
      "0         982\n",
      "1         119\n",
      "\n",
      "Feature groups: {'Panel_A': 6, 'Panel_B': 7, 'Panel_C': 8, 'Panel_D': 7, 'Panel_E': 8, 'All_Biomarkers': 36, 'Reproductive': 12, 'Lifestyle': 18, 'Family_History': 6, 'Clinical_Lifestyle': 44}\n",
      "\n",
      "Quantum Entropy Results:\n",
      "- Panel_A: 0.0006\n",
      "- Panel_B: 1.3632\n",
      "- Panel_C: 0.0058\n",
      "- Panel_D: 1.6022\n",
      "- Panel_E: 2.4042\n",
      "- Reproductive: 3.0290\n",
      "- Lifestyle: 1.9183\n",
      "- Family_History: 1.2661\n",
      "- All_Biomarkers: 1.0000\n",
      "- Clinical_Lifestyle: 0.8189\n",
      "\n",
      "Synergy Metrics:\n",
      "AUC-ROC: 0.707 ± 0.073\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PLCO Console Report: Quantum Entropy + Group Summary + AUC\n",
    "# Reproduces the \"Analyzing PLCO dataset\" style printout\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import eigh\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "FILE =  r\"D:\\Lakshmi Kumari\\merged_oc_ovars.csv\"      # change path if needed\n",
    "LABEL_COL = \"is_case\"               # 0/1\n",
    "DEC = 4                             # print precision for vNE\n",
    "\n",
    "# Panel prefixes (exactly like your dataset)\n",
    "PANEL_PREFIX = {\n",
    "    \"Panel_A\": \"panela_\",\n",
    "    \"Panel_B\": \"panelb_\",\n",
    "    \"Panel_C\": \"panelc_\",\n",
    "    \"Panel_D\": \"paneld_\",\n",
    "    \"Panel_E\": \"panele_\",\n",
    "}\n",
    "\n",
    "# Keyword buckets (edit if your column names differ)\n",
    "KEYWORDS = {\n",
    "    # classical reproductive markers / gyneco history\n",
    "    \"Reproductive\": [\n",
    "        \"menarche\", \"menopause\", \"post_menopausal\", \"parity\",\n",
    "        \"preg\", \"hyst\", \"bcontr\", \"ovariesr\", \"horm_stat\", \"horm_f\"\n",
    "    ],\n",
    "    # lifestyle / anthropometrics\n",
    "    \"Lifestyle\": [\n",
    "        \"bmi\", \"height\", \"weight\", \"smok\", \"cig\", \"alcohol\", \"pack_years\", \"race\", \"hispanic\"\n",
    "    ],\n",
    "    # family history\n",
    "    \"Family_History\": [\n",
    "        \"fam_\", \"family\", \"mother\", \"sister\", \"relative\", \"polyps_f\", \"arthrit_f\", \"osteopor_f\", \"divertic_f\", \"gallblad_f\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Clinical_Lifestyle = a broader join of Reproductive + Lifestyle (+ a few extras)\n",
    "CLINICAL_EXTRAS = [\n",
    "    \"eligible\", \"sqx\", \"dhq\", \"bq_age\", \"preg_f\", \"horm_\", \"menstrs_stat_type\"\n",
    "]\n",
    "# ---------------------------\n",
    "\n",
    "def vne_entropy(X: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Von Neumann entropy of covariance-derived density matrix.\"\"\"\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    # center + mean-impute to stabilize covariance\n",
    "    X = X - np.nanmean(X, axis=0, keepdims=True)\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    inds = np.where(np.isnan(X))\n",
    "    if inds[0].size:\n",
    "        X[inds] = np.take(col_means, inds[1])\n",
    "    C = np.cov(X, rowvar=False)\n",
    "    tr = np.trace(C)\n",
    "    if tr <= eps:\n",
    "        return 0.0\n",
    "    rho = C / tr\n",
    "    vals = eigh(rho, UPLO=\"U\")[0]\n",
    "    vals = vals[vals > eps]\n",
    "    return float(-(vals * np.log2(vals)).sum())\n",
    "\n",
    "def columns_by_prefix(df: pd.DataFrame, prefix: str):\n",
    "    return [c for c in df.columns if str(c).startswith(prefix)]\n",
    "\n",
    "def columns_by_keywords(df: pd.DataFrame, words):\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        s = str(c).lower()\n",
    "        if any(w in s for w in words):\n",
    "            cols.append(c)\n",
    "    return sorted(list(set(cols)))\n",
    "\n",
    "def make_groups(df: pd.DataFrame):\n",
    "    groups = {}\n",
    "    # Panels by prefix\n",
    "    for g, pref in PANEL_PREFIX.items():\n",
    "        groups[g] = columns_by_prefix(df, pref)\n",
    "\n",
    "    # All_Biomarkers = union of all panel columns\n",
    "    biomarker_cols = sorted({c for glist in groups.values() for c in glist})\n",
    "    groups[\"All_Biomarkers\"] = biomarker_cols\n",
    "\n",
    "    # Reproductive / Lifestyle / Family_History by keywords (excluding panel columns)\n",
    "    remaining_cols = [c for c in df.columns if c not in biomarker_cols + [LABEL_COL]]\n",
    "\n",
    "    groups[\"Reproductive\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Reproductive\"])]\n",
    "    groups[\"Lifestyle\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Lifestyle\"])]\n",
    "    groups[\"Family_History\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Family_History\"])]\n",
    "\n",
    "    # Clinical_Lifestyle = Lifestyle ∪ Reproductive plus a few extra clinical admin bits\n",
    "    clin = set(groups[\"Lifestyle\"]) | set(groups[\"Reproductive\"])\n",
    "    clin |= set([c for c in remaining_cols if any(k in c.lower() for k in CLINICAL_EXTRAS)])\n",
    "    groups[\"Clinical_Lifestyle\"] = sorted(list(clin))\n",
    "\n",
    "    return groups\n",
    "\n",
    "def entropy_report(df: pd.DataFrame, groups: dict):\n",
    "    # compute vNE for each group, normalized to All_Biomarkers\n",
    "    vne = {}\n",
    "    for g, cols in groups.items():\n",
    "        if len(cols) == 0:\n",
    "            vne[g] = np.nan\n",
    "        else:\n",
    "            vne[g] = vne_entropy(df[cols].to_numpy())\n",
    "    base = vne.get(\"All_Biomarkers\", np.nan)\n",
    "    norm = {g: (v/base if (base and base > 0) else np.nan) for g, v in vne.items()}\n",
    "\n",
    "    order = [\"Panel_A\",\"Panel_B\",\"Panel_C\",\"Panel_D\",\"Panel_E\",\n",
    "             \"Reproductive\",\"Lifestyle\",\"Family_History\",\"All_Biomarkers\",\"Clinical_Lifestyle\"]\n",
    "\n",
    "    lines = []\n",
    "    for g in order:\n",
    "        if g in vne and not np.isnan(vne[g]):\n",
    "            lines.append((g, round(vne[g], DEC), round(norm[g], DEC)))\n",
    "    return lines\n",
    "\n",
    "def quick_auc(df: pd.DataFrame, Xcols, y, seed=7):\n",
    "    clf = GradientBoostingClassifier(random_state=seed)\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores = cross_val_score(pipe, df[Xcols], y, cv=cv, scoring=\"roc_auc\")\n",
    "    return float(scores.mean()), float(scores.std())\n",
    "\n",
    "# =========================\n",
    "# Main pretty print report\n",
    "# =========================\n",
    "df = pd.read_csv(FILE)\n",
    "print(\"\\nPLCO\")\n",
    "print(\"================================\")\n",
    "print(\"Analyzing PLCO dataset\")\n",
    "print(\"================================\")\n",
    "\n",
    "# Basic stats\n",
    "n = len(df)\n",
    "assert LABEL_COL in df.columns, f\"Label '{LABEL_COL}' not found.\"\n",
    "y = df[LABEL_COL].astype(int)\n",
    "pos = int((y == 1).sum())\n",
    "neg = n - pos\n",
    "bal = pos / max(1, n)\n",
    "\n",
    "print(f\"✅ Loaded PLCO: {n} samples, {df.drop(columns=[LABEL_COL]).shape[1]} features, target balance = {bal:.2f}\")\n",
    "print(f\"Loaded {n} rows. Target distribution:\")\n",
    "print(y.value_counts().rename_axis('target').to_frame('count'))\n",
    "print()\n",
    "\n",
    "# Grouping\n",
    "groups = make_groups(df)\n",
    "group_sizes = {k: len(v) for k, v in groups.items()}\n",
    "print(\"Feature groups:\", group_sizes)\n",
    "print()\n",
    "\n",
    "# Entropy block\n",
    "print(\"Quantum Entropy Results:\")\n",
    "ent_lines = entropy_report(df, groups)\n",
    "for g, v, vn in ent_lines:\n",
    "    print(f\"- {g}: {vn:.4f}\")\n",
    "print()\n",
    "\n",
    "# AUC sanity (use All_Biomarkers to reflect the “Synergy Metrics” line style)\n",
    "if len(groups[\"All_Biomarkers\"]) > 0:\n",
    "    auc_mean, auc_std = quick_auc(df, groups[\"All_Biomarkers\"], y)\n",
    "    print(\"Synergy Metrics:\")\n",
    "    print(f\"AUC-ROC: {auc_mean:.3f} ± {auc_std:.3f}\")\n",
    "else:\n",
    "    print(\"Synergy Metrics:\")\n",
    "    print(\"AUC-ROC: n/a (no biomarker columns found)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f392d248-d6ae-4e7a-9135-f50516d84680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Biomarker Metrics Logger (Notebook Version)\n",
    "# - Paste this cell once near the top of your notebook.\n",
    "# - Call `compute_basic_metrics(...)` for each run,\n",
    "#   then `logger.log_panel(...)` or `logger.log_pair(...)`.\n",
    "# - Finally call `logger.export_all()` to get an Excel workbook + PNG figures.\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: sklearn metrics (falls back gracefully if missing)\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, brier_score_loss\n",
    "except Exception:\n",
    "    roc_auc_score = None\n",
    "    accuracy_score = None\n",
    "    f1_score = None\n",
    "    brier_score_loss = None\n",
    "\n",
    "# --------------------------\n",
    "# Metric helpers\n",
    "# --------------------------\n",
    "\n",
    "def expected_calibration_error(y_true: np.ndarray, y_prob: np.ndarray, n_bins: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    ECE with equal-width bins over [0,1].\n",
    "    y_true: shape [N] in {0,1}\n",
    "    y_prob: shape [N] in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.clip(np.asarray(y_prob), 0.0, 1.0)\n",
    "\n",
    "    edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    N = len(y_true)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = edges[i], edges[i+1]\n",
    "        mask = (y_prob >= lo) & (y_prob < hi) if i < n_bins - 1 else (y_prob >= lo) & (y_prob <= hi)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        conf = y_prob[mask].mean()\n",
    "        acc = y_true[mask].mean()\n",
    "        ece += (mask.sum() / N) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def compute_basic_metrics(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    y_pred: Optional[np.ndarray] = None,\n",
    "    n_bins: int = 10,\n",
    "    positive_label: int = 1,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute AUROC, Accuracy, Macro-F1, Brier, and ECE for binary classification.\n",
    "    - y_true: 0/1 labels\n",
    "    - y_prob: predicted probability for the positive class\n",
    "    - y_pred: optional; if None, uses threshold 0.5\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    if y_pred is None:\n",
    "        y_pred = (y_prob >= 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Defaults (no sklearn)\n",
    "    auroc = np.nan\n",
    "    acc = float((y_pred == y_true).mean())\n",
    "    macro_f1 = np.nan\n",
    "    brier = float(np.mean((y_prob - (y_true == positive_label).astype(float))**2))\n",
    "    ece = expected_calibration_error((y_true == positive_label).astype(int), y_prob, n_bins=n_bins)\n",
    "\n",
    "    # sklearn-enabled (if available)\n",
    "    if roc_auc_score is not None:\n",
    "        try:\n",
    "            auroc = float(roc_auc_score((y_true == positive_label).astype(int), y_prob))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if f1_score is not None:\n",
    "        try:\n",
    "            macro_f1 = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if brier_score_loss is not None:\n",
    "        try:\n",
    "            brier = float(brier_score_loss((y_true == positive_label).astype(int), y_prob))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # rounded outputs\n",
    "    def r(x): \n",
    "        return (None if x is None else (np.nan if isinstance(x, float) and np.isnan(x) else round(float(x), 6)))\n",
    "\n",
    "    return dict(\n",
    "        auroc=r(auroc),\n",
    "        accuracy=r(acc),\n",
    "        macro_f1=r(macro_f1),\n",
    "        brier=r(brier),\n",
    "        ece=r(ece),\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Logger\n",
    "# --------------------------\n",
    "\n",
    "@dataclass\n",
    "class MetricsLogger:\n",
    "    out_dir: str = \"results_metrics\"\n",
    "    panels_rows: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    pairs_rows: List[Dict[str, Any]] = field(default_factory=list)\n",
    "\n",
    "    def log_panel(\n",
    "        self,\n",
    "        panel_name: str,\n",
    "        n_samples: int,\n",
    "        auroc: Optional[float] = None,\n",
    "        accuracy: Optional[float] = None,\n",
    "        macro_f1: Optional[float] = None,\n",
    "        brier: Optional[float] = None,\n",
    "        ece: Optional[float] = None,\n",
    "        vne_mean: Optional[float] = None,\n",
    "        vne_lo: Optional[float] = None,\n",
    "        vne_hi: Optional[float] = None,\n",
    "        extra: Optional[Dict[str, Any]] = None,\n",
    "    ) -> None:\n",
    "        row = dict(\n",
    "            panel=panel_name,\n",
    "            auroc=auroc,\n",
    "            accuracy=accuracy,\n",
    "            macro_f1=macro_f1,\n",
    "            brier=brier,\n",
    "            ece=ece,\n",
    "            vne_mean=vne_mean,\n",
    "            vne_lo=vne_lo,\n",
    "            vne_hi=vne_hi,\n",
    "            n_samples=int(n_samples),\n",
    "        )\n",
    "        if extra: row.update(extra)\n",
    "        self.panels_rows.append(row)\n",
    "\n",
    "    def log_pair(\n",
    "        self,\n",
    "        pair_label: str,\n",
    "        n_samples: int,\n",
    "        auroc: Optional[float] = None,\n",
    "        accuracy: Optional[float] = None,\n",
    "        macro_f1: Optional[float] = None,\n",
    "        brier: Optional[float] = None,\n",
    "        ece: Optional[float] = None,\n",
    "        vne_mean: Optional[float] = None,\n",
    "        vne_lo: Optional[float] = None,\n",
    "        vne_hi: Optional[float] = None,\n",
    "        extra: Optional[Dict[str, Any]] = None,\n",
    "    ) -> None:\n",
    "        row = dict(\n",
    "            panel_pair=pair_label,\n",
    "            auroc=auroc,\n",
    "            accuracy=accuracy,\n",
    "            macro_f1=macro_f1,\n",
    "            brier=brier,\n",
    "            ece=ece,\n",
    "            vne_mean=vne_mean,\n",
    "            vne_lo=vne_lo,\n",
    "            vne_hi=vne_hi,\n",
    "            n_samples=int(n_samples),\n",
    "        )\n",
    "        if extra: row.update(extra)\n",
    "        self.pairs_rows.append(row)\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_ranks(df: pd.DataFrame, keys: Tuple[str, ...] = (\"auroc\",\"macro_f1\",\"brier\",\"ece\",\"vne_mean\")) -> pd.DataFrame:\n",
    "        \"\"\"Create metric-wise ranks and an overall composite rank (sum of ranks).\"\"\"\n",
    "        if df.empty:\n",
    "            return df\n",
    "        df = df.copy()\n",
    "        lower_better = {\"brier\",\"ece\"}\n",
    "        for k in keys:\n",
    "            if k not in df.columns:\n",
    "                df[k] = np.nan\n",
    "            asc = (k in lower_better)  # lower is better for brier/ece\n",
    "            df[f\"rank_{k}\"] = df[k].rank(ascending=asc, method=\"min\")\n",
    "        rank_cols = [c for c in df.columns if c.startswith(\"rank_\")]\n",
    "        df[\"rank_sum\"] = df[rank_cols].sum(axis=1)\n",
    "        df[\"rank_overall\"] = df[\"rank_sum\"].rank(ascending=True, method=\"min\")\n",
    "        return df\n",
    "\n",
    "    def export_all(self) -> Tuple[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Writes:\n",
    "          - Excel workbook with Panels_Summary, Pairs_Summary, Top5 sheets\n",
    "          - Figures (PNG): per-panel AUROC, per-panel vNE±CI, per-pair Composite Rank,\n",
    "                           Top-10 AUROC pairs, Top-10 ECE pairs\n",
    "        Returns: (excel_path, dict_of_figure_paths)\n",
    "        \"\"\"\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        out_dir = Path(self.out_dir)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Build dataframes\n",
    "        df_panels = pd.DataFrame(self.panels_rows) if self.panels_rows else pd.DataFrame(columns=[\n",
    "            \"panel\",\"auroc\",\"accuracy\",\"macro_f1\",\"brier\",\"ece\",\"vne_mean\",\"vne_lo\",\"vne_hi\",\"n_samples\"\n",
    "        ])\n",
    "        df_pairs  = pd.DataFrame(self.pairs_rows) if self.pairs_rows else pd.DataFrame(columns=[\n",
    "            \"panel_pair\",\"auroc\",\"accuracy\",\"macro_f1\",\"brier\",\"ece\",\"vne_mean\",\"vne_lo\",\"vne_hi\",\"n_samples\"\n",
    "        ])\n",
    "\n",
    "        df_panels_ranked = self._add_ranks(df_panels)\n",
    "        df_pairs_ranked  = self._add_ranks(df_pairs)\n",
    "\n",
    "        # Excel\n",
    "        excel_path = str(out_dir / f\"biomarker_metrics_{ts}.xlsx\")\n",
    "        with pd.ExcelWriter(excel_path, engine=\"xlsxwriter\") as writer:\n",
    "            df_panels_ranked.sort_values(\"rank_overall\", na_position=\"last\").to_excel(writer, index=False, sheet_name=\"Panels_Summary\")\n",
    "            df_pairs_ranked.sort_values(\"rank_overall\", na_position=\"last\").to_excel(writer, index=False, sheet_name=\"Pairs_Summary\")\n",
    "            if not df_panels_ranked.empty:\n",
    "                df_panels_ranked.sort_values(\"rank_overall\").head(5).to_excel(writer, index=False, sheet_name=\"Top5_Panels\")\n",
    "            if not df_pairs_ranked.empty:\n",
    "                df_pairs_ranked.sort_values(\"rank_overall\").head(5).to_excel(writer, index=False, sheet_name=\"Top5_Pairs\")\n",
    "\n",
    "        # Figures (one per plot; no seaborn, no explicit colors)\n",
    "        figs = {}\n",
    "        figs_dir = out_dir / f\"figs_{ts}\"\n",
    "        figs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not df_panels_ranked.empty:\n",
    "            try:\n",
    "                plt.figure()\n",
    "                order = df_panels_ranked.sort_values(\"auroc\", ascending=False)\n",
    "                plt.bar(order[\"panel\"], order[\"auroc\"])\n",
    "                plt.xticks(rotation=45, ha=\"right\")\n",
    "                plt.ylabel(\"AUROC\")\n",
    "                plt.title(\"Per-Panel AUROC\")\n",
    "                plt.tight_layout()\n",
    "                p = str(figs_dir / \"auroc_by_panel.png\")\n",
    "                plt.savefig(p, dpi=200); plt.close()\n",
    "                figs[\"auroc_by_panel\"] = p\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                plt.figure()\n",
    "                idx = np.arange(len(df_panels_ranked))\n",
    "                vmean = pd.to_numeric(df_panels_ranked[\"vne_mean\"], errors=\"coerce\")\n",
    "                vlo = pd.to_numeric(df_panels_ranked[\"vne_lo\"], errors=\"coerce\")\n",
    "                vhi = pd.to_numeric(df_panels_ranked[\"vne_hi\"], errors=\"coerce\")\n",
    "                yerr = np.vstack([vmean - vlo, vhi - vmean])\n",
    "                yerr = np.nan_to_num(yerr, nan=0.0)\n",
    "                plt.errorbar(idx, vmean, yerr=yerr, fmt='o')\n",
    "                plt.xticks(idx, df_panels_ranked[\"panel\"], rotation=45, ha=\"right\")\n",
    "                plt.ylabel(\"vNE (mean ± CI)\")\n",
    "                plt.title(\"Per-Panel von Neumann Entropy\")\n",
    "                plt.tight_layout()\n",
    "                p = str(figs_dir / \"vne_by_panel.png\")\n",
    "                plt.savefig(p, dpi=200); plt.close()\n",
    "                figs[\"vne_by_panel\"] = p\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if not df_pairs_ranked.empty:\n",
    "            try:\n",
    "                plt.figure()\n",
    "                orderp = df_pairs_ranked.sort_values(\"rank_overall\")\n",
    "                plt.bar(orderp[\"panel_pair\"], orderp[\"rank_overall\"])\n",
    "                plt.xticks(rotation=45, ha=\"right\")\n",
    "                plt.ylabel(\"Composite Rank (lower is better)\")\n",
    "                plt.title(\"Per-Pair Composite Rank\")\n",
    "                plt.tight_layout()\n",
    "                p = str(figs_dir / \"composite_rank_by_pair.png\")\n",
    "                plt.savefig(p, dpi=200); plt.close()\n",
    "                figs[\"composite_rank_by_pair\"] = p\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                plt.figure()\n",
    "                orderp10 = df_pairs_ranked.sort_values(\"auroc\", ascending=False).head(10)\n",
    "                plt.bar(orderp10[\"panel_pair\"], orderp10[\"auroc\"])\n",
    "                plt.xticks(rotation=45, ha=\"right\")\n",
    "                plt.ylabel(\"AUROC\")\n",
    "                plt.title(\"Top 10 Pairs by AUROC\")\n",
    "                plt.tight_layout()\n",
    "                p = str(figs_dir / \"auroc_top10_pairs.png\")\n",
    "                plt.savefig(p, dpi=200); plt.close()\n",
    "                figs[\"auroc_top10_pairs\"] = p\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                plt.figure()\n",
    "                orderp10_ece = df_pairs_ranked.sort_values(\"ece\", ascending=True).head(10)\n",
    "                plt.bar(orderp10_ece[\"panel_pair\"], orderp10_ece[\"ece\"])\n",
    "                plt.xticks(rotation=45, ha=\"right\")\n",
    "                plt.ylabel(\"ECE\")\n",
    "                plt.title(\"Top 10 Pairs by Calibration (ECE)\")\n",
    "                plt.tight_layout()\n",
    "                p = str(figs_dir / \"ece_top10_pairs.png\")\n",
    "                plt.savefig(p, dpi=200); plt.close()\n",
    "                figs[\"ece_top10_pairs\"] = p\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        print(\"✅ Export complete\")\n",
    "        print(\"Excel:\", excel_path)\n",
    "        print(\"Figures:\", figs)\n",
    "        return excel_path, figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70906231-8b4e-4310-a146-bb257c908049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLCO\n",
      "================================\n",
      "Analyzing PLCO dataset\n",
      "================================\n",
      "✅ Loaded PLCO: 1101 samples, 177 features, target balance = 0.11\n",
      "Loaded 1101 rows. Target distribution:\n",
      "        count\n",
      "target       \n",
      "0         982\n",
      "1         119\n",
      "\n",
      "Feature groups: {'Panel_A': 6, 'Panel_B': 7, 'Panel_C': 8, 'Panel_D': 7, 'Panel_E': 8, 'All_Biomarkers': 36, 'Reproductive': 12, 'Lifestyle': 18, 'Family_History': 6, 'Clinical_Lifestyle': 44}\n",
      "\n",
      "\n",
      "Quantum Entropy Results (vNE normalized to All_Biomarkers):\n",
      "- Panel_A: 0.0006\n",
      "- Panel_B: 1.3632\n",
      "- Panel_C: 0.0058\n",
      "- Panel_D: 1.6022\n",
      "- Panel_E: 2.4042\n",
      "- All_Biomarkers: 1.0000\n",
      "- Reproductive: 3.0290\n",
      "- Lifestyle: 1.9183\n",
      "- Family_History: 1.2661\n",
      "- Clinical_Lifestyle: 0.8189\n",
      "\n",
      "Synergy Metrics (All_Biomarkers baseline):\n",
      "AUC-ROC: 0.703\n",
      "\n",
      "✅ Export complete\n",
      "Excel: OC_Quantum_results\\biomarker_metrics_20260207_061107.xlsx\n",
      "Figures: {'auroc_by_panel': 'OC_Quantum_results\\\\figs_20260207_061107\\\\auroc_by_panel.png', 'vne_by_panel': 'OC_Quantum_results\\\\figs_20260207_061107\\\\vne_by_panel.png', 'composite_rank_by_pair': 'OC_Quantum_results\\\\figs_20260207_061107\\\\composite_rank_by_pair.png', 'auroc_top10_pairs': 'OC_Quantum_results\\\\figs_20260207_061107\\\\auroc_top10_pairs.png', 'ece_top10_pairs': 'OC_Quantum_results\\\\figs_20260207_061107\\\\ece_top10_pairs.png'}\n",
      "Best pair (composite rank): B+E\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# PLCO Biomarker Metrics: Panels + Pairs (Clean Rerun, No Dummy Numbers)\n",
    "# - Uses out-of-fold probabilities for metrics (AUROC/Acc/F1/Brier/ECE)\n",
    "# - Computes vNE + bootstrap CI; normalizes vNE by All_Biomarkers\n",
    "# - Exports timestamped Excel + PNG figures (Matplotlib; no seaborn/colors)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "FILE =  r\"D:\\Lakshmi Kumari\\merged_oc_ovars.csv\"      # change path if needed\n",
    "LABEL_COL = \"is_case\"               # 0/1\n",
    "DEC = 4                             # print precision for vNE in console\n",
    "N_SPLITS = 5                        # CV splits\n",
    "SEED = 7                            # reproducibility\n",
    "N_BOOT_VNE = 200                    # bootstrap iterations for vNE CI (set 0 to skip)\n",
    "OUT_DIR = \"OC_Quantum_results\"         # output folder\n",
    "# ---------------------------\n",
    "\n",
    "# Panel prefixes (exactly like your dataset)\n",
    "PANEL_PREFIX = {\n",
    "    \"Panel_A\": \"panela_\",\n",
    "    \"Panel_B\": \"panelb_\",\n",
    "    \"Panel_C\": \"panelc_\",\n",
    "    \"Panel_D\": \"paneld_\",\n",
    "    \"Panel_E\": \"panele_\",\n",
    "}\n",
    "\n",
    "# Keyword buckets (edit if your column names differ)\n",
    "KEYWORDS = {\n",
    "    \"Reproductive\": [\n",
    "        \"menarche\", \"menopause\", \"post_menopausal\", \"parity\",\n",
    "        \"preg\", \"hyst\", \"bcontr\", \"ovariesr\", \"horm_stat\", \"horm_f\"\n",
    "    ],\n",
    "    \"Lifestyle\": [\n",
    "        \"bmi\", \"height\", \"weight\", \"smok\", \"cig\", \"alcohol\", \"pack_years\", \"race\", \"hispanic\"\n",
    "    ],\n",
    "    \"Family_History\": [\n",
    "        \"fam_\", \"family\", \"mother\", \"sister\", \"relative\",\n",
    "        \"polyps_f\", \"arthrit_f\", \"osteopor_f\", \"divertic_f\", \"gallblad_f\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Clinical_Lifestyle = Lifestyle ∪ Reproductive plus a few extras\n",
    "CLINICAL_EXTRAS = [\n",
    "    \"eligible\", \"sqx\", \"dhq\", \"bq_age\", \"preg_f\", \"horm_\", \"menstrs_stat_type\"\n",
    "]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Helpers: vNE, grouping, metrics\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def vne_entropy(X: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Von Neumann entropy of covariance-derived density matrix.\"\"\"\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    X = X - np.nanmean(X, axis=0, keepdims=True)\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    inds = np.where(np.isnan(X))\n",
    "    if inds[0].size:\n",
    "        X[inds] = np.take(col_means, inds[1])\n",
    "    C = np.cov(X, rowvar=False)\n",
    "    tr = np.trace(C)\n",
    "    if tr <= eps:\n",
    "        return 0.0\n",
    "    rho = C / tr\n",
    "    vals = eigh(rho, UPLO=\"U\")[0]\n",
    "    vals = vals[vals > eps]\n",
    "    return float(-(vals * np.log2(vals)).sum())\n",
    "\n",
    "def columns_by_prefix(df: pd.DataFrame, prefix: str):\n",
    "    return [c for c in df.columns if str(c).startswith(prefix)]\n",
    "\n",
    "def make_groups(df: pd.DataFrame):\n",
    "    groups = {}\n",
    "    # Panels by prefix\n",
    "    for g, pref in PANEL_PREFIX.items():\n",
    "        groups[g] = columns_by_prefix(df, pref)\n",
    "\n",
    "    # All_Biomarkers = union of all panel columns\n",
    "    biomarker_cols = sorted({c for glist in groups.values() for c in glist})\n",
    "    groups[\"All_Biomarkers\"] = biomarker_cols\n",
    "\n",
    "    # Reproductive / Lifestyle / Family_History by keywords (excluding panel columns)\n",
    "    remaining_cols = [c for c in df.columns if c not in biomarker_cols + [LABEL_COL]]\n",
    "\n",
    "    groups[\"Reproductive\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Reproductive\"])]\n",
    "    groups[\"Lifestyle\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Lifestyle\"])]\n",
    "    groups[\"Family_History\"] = [c for c in remaining_cols if any(k in c.lower() for k in KEYWORDS[\"Family_History\"])]\n",
    "\n",
    "    # Clinical_Lifestyle\n",
    "    clin = set(groups[\"Lifestyle\"]) | set(groups[\"Reproductive\"])\n",
    "    clin |= set([c for c in remaining_cols if any(k in c.lower() for k in CLINICAL_EXTRAS)])\n",
    "    groups[\"Clinical_Lifestyle\"] = sorted(list(clin))\n",
    "\n",
    "    return groups\n",
    "\n",
    "def expected_calibration_error(y_true: np.ndarray, y_prob: np.ndarray, n_bins: int = 10) -> float:\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.clip(np.asarray(y_prob), 0.0, 1.0)\n",
    "    edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    N = len(y_true)\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = edges[i], edges[i+1]\n",
    "        mask = (y_prob >= lo) & (y_prob < hi) if i < n_bins - 1 else (y_prob >= lo) & (y_prob <= hi)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        conf = y_prob[mask].mean()\n",
    "        acc = y_true[mask].mean()\n",
    "        ece += (mask.sum() / N) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def oof_metrics(df: pd.DataFrame, Xcols, y, n_splits=5, seed=7):\n",
    "    \"\"\"Out-of-fold probabilities -> AUROC, Acc, Macro-F1, Brier, ECE.\"\"\"\n",
    "    if len(Xcols) == 0:\n",
    "        return dict(auroc=np.nan, accuracy=np.nan, macro_f1=np.nan, brier=np.nan, ece=np.nan, n=len(y))\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=seed)),\n",
    "    ])\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    # Get OOF probabilities for positive class\n",
    "    prob = cross_val_predict(pipe, df[Xcols], y, cv=skf, method=\"predict_proba\")[:, 1]\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        auroc=float(roc_auc_score(y, prob)),\n",
    "        accuracy=float(accuracy_score(y, pred)),\n",
    "        macro_f1=float(f1_score(y, pred, average=\"macro\")),\n",
    "        brier=float(brier_score_loss(y, prob)),\n",
    "        ece=float(expected_calibration_error(y, prob, n_bins=10)),\n",
    "        n=len(y),\n",
    "    )\n",
    "\n",
    "def vne_with_ci(df: pd.DataFrame, cols, n_boot=200, seed=7):\n",
    "    \"\"\"Point vNE + bootstrap CI (percentiles).\"\"\"\n",
    "    if len(cols) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    X = df[cols].to_numpy()\n",
    "    v = vne_entropy(X)\n",
    "    if n_boot <= 0:\n",
    "        return v, np.nan, np.nan\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = X.shape[0]\n",
    "    boots = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, N, N)\n",
    "        boots.append(vne_entropy(X[idx]))\n",
    "    lo, hi = np.percentile(boots, [2.5, 97.5])\n",
    "    return float(v), float(lo), float(hi)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Load data\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(FILE)\n",
    "print(\"\\nPLCO\")\n",
    "print(\"================================\")\n",
    "print(\"Analyzing PLCO dataset\")\n",
    "print(\"================================\")\n",
    "\n",
    "# Basic stats\n",
    "n = len(df)\n",
    "assert LABEL_COL in df.columns, f\"Label '{LABEL_COL}' not found.\"\n",
    "y = df[LABEL_COL].astype(int).to_numpy()\n",
    "pos = int((y == 1).sum()); neg = n - pos\n",
    "bal = pos / max(1, n)\n",
    "\n",
    "print(f\"✅ Loaded PLCO: {n} samples, {df.drop(columns=[LABEL_COL]).shape[1]} features, target balance = {bal:.2f}\")\n",
    "print(f\"Loaded {n} rows. Target distribution:\")\n",
    "print(pd.Series(y).value_counts().rename_axis('target').to_frame('count'))\n",
    "print()\n",
    "\n",
    "# Grouping\n",
    "groups = make_groups(df)\n",
    "group_sizes = {k: len(v) for k, v in groups.items()}\n",
    "print(\"Feature groups:\", group_sizes)\n",
    "print()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Compute vNE (normalized) + metrics for each group; and for all panel PAIRS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# vNE normalization base\n",
    "vne_all, vne_all_lo, vne_all_hi = vne_with_ci(df, groups[\"All_Biomarkers\"], n_boot=N_BOOT_VNE, seed=SEED)\n",
    "def vne_norm(v):\n",
    "    return (v / vne_all) if (isinstance(v, (int, float)) and vne_all and vne_all > 0) else np.nan\n",
    "\n",
    "# Per-panel & keyword groups\n",
    "rows_panels = []\n",
    "for gname, cols in groups.items():\n",
    "    # skip empty sets cleanly\n",
    "    v, lo, hi = vne_with_ci(df, cols, n_boot=N_BOOT_VNE, seed=SEED)\n",
    "    metrics = oof_metrics(df, cols, y, n_splits=N_SPLITS, seed=SEED) if gname != \"All_Biomarkers\" or len(cols) > 0 \\\n",
    "              else dict(auroc=np.nan, accuracy=np.nan, macro_f1=np.nan, brier=np.nan, ece=np.nan, n=len(y))\n",
    "    rows_panels.append({\n",
    "        \"panel\": gname,\n",
    "        \"auroc\": metrics[\"auroc\"],\n",
    "        \"accuracy\": metrics[\"accuracy\"],\n",
    "        \"macro_f1\": metrics[\"macro_f1\"],\n",
    "        \"brier\": metrics[\"brier\"],\n",
    "        \"ece\": metrics[\"ece\"],\n",
    "        \"vne_mean\": v,\n",
    "        \"vne_lo\": lo,\n",
    "        \"vne_hi\": hi,\n",
    "        \"vne_norm\": vne_norm(v),\n",
    "        \"n_samples\": metrics[\"n\"],\n",
    "        \"n_features\": len(cols),\n",
    "    })\n",
    "\n",
    "# Panel pairs among A..E\n",
    "def panel_cols(name):\n",
    "    return groups.get(name, [])\n",
    "\n",
    "core_panels = [\"Panel_A\",\"Panel_B\",\"Panel_C\",\"Panel_D\",\"Panel_E\"]\n",
    "rows_pairs = []\n",
    "for i in range(len(core_panels)):\n",
    "    for j in range(i+1, len(core_panels)):\n",
    "        pa, pb = core_panels[i], core_panels[j]\n",
    "        label = f\"{pa.split('_')[1]}+{pb.split('_')[1]}\"  # \"A+C\" style\n",
    "        cols = sorted(list(set(panel_cols(pa)) | set(panel_cols(pb))))\n",
    "        v, lo, hi = vne_with_ci(df, cols, n_boot=N_BOOT_VNE, seed=SEED)\n",
    "        metrics = oof_metrics(df, cols, y, n_splits=N_SPLITS, seed=SEED)\n",
    "        rows_pairs.append({\n",
    "            \"panel_pair\": label,\n",
    "            \"auroc\": metrics[\"auroc\"],\n",
    "            \"accuracy\": metrics[\"accuracy\"],\n",
    "            \"macro_f1\": metrics[\"macro_f1\"],\n",
    "            \"brier\": metrics[\"brier\"],\n",
    "            \"ece\": metrics[\"ece\"],\n",
    "            \"vne_mean\": v,\n",
    "            \"vne_lo\": lo,\n",
    "            \"vne_hi\": hi,\n",
    "            \"vne_norm\": vne_norm(v),\n",
    "            \"n_samples\": metrics[\"n\"],\n",
    "            \"n_features\": len(cols),\n",
    "        })\n",
    "\n",
    "df_panels = pd.DataFrame(rows_panels)\n",
    "df_pairs  = pd.DataFrame(rows_pairs)\n",
    "\n",
    "# Rankers\n",
    "def add_ranks(df, keys=(\"auroc\",\"macro_f1\",\"brier\",\"ece\",\"vne_mean\")):\n",
    "    df = df.copy()\n",
    "    lower_better = {\"brier\",\"ece\"}\n",
    "    for k in keys:\n",
    "        if k not in df.columns:\n",
    "            df[k] = np.nan\n",
    "        asc = (k in lower_better)\n",
    "        df[f\"rank_{k}\"] = df[k].rank(ascending=asc, method=\"min\")\n",
    "    rank_cols = [c for c in df.columns if c.startswith(\"rank_\")]\n",
    "    df[\"rank_sum\"] = df[rank_cols].sum(axis=1)\n",
    "    df[\"rank_overall\"] = df[\"rank_sum\"].rank(ascending=True, method=\"min\")\n",
    "    return df\n",
    "\n",
    "df_panels_ranked = add_ranks(df_panels)\n",
    "df_pairs_ranked  = add_ranks(df_pairs)\n",
    "\n",
    "best_pair = df_pairs_ranked.sort_values(\"rank_overall\").iloc[0][\"panel_pair\"] if not df_pairs_ranked.empty else None\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Export Excel + Figures\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "excel_path = str(Path(OUT_DIR) / f\"biomarker_metrics_{ts}.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"xlsxwriter\") as writer:\n",
    "    df_panels_ranked.sort_values(\"rank_overall\", na_position=\"last\").to_excel(writer, index=False, sheet_name=\"Panels_Summary\")\n",
    "    df_pairs_ranked.sort_values(\"rank_overall\", na_position=\"last\").to_excel(writer, index=False, sheet_name=\"Pairs_Summary\")\n",
    "    if not df_panels_ranked.empty:\n",
    "        df_panels_ranked.sort_values(\"rank_overall\").head(5).to_excel(writer, index=False, sheet_name=\"Top5_Panels\")\n",
    "    if not df_pairs_ranked.empty:\n",
    "        df_pairs_ranked.sort_values(\"rank_overall\").head(5).to_excel(writer, index=False, sheet_name=\"Top5_Pairs\")\n",
    "    # Notes\n",
    "    notes = pd.DataFrame({\n",
    "        \"notes\": [f\"Generated at {datetime.now().isoformat()}\",\n",
    "                  f\"Best pair by composite rank: {best_pair}\"]\n",
    "    })\n",
    "    notes.to_excel(writer, index=False, sheet_name=\"Notes\")\n",
    "\n",
    "# Figures (no styles/colors; one chart per fig)\n",
    "fig_dir = Path(OUT_DIR) / f\"figs_{ts}\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "figs = {}\n",
    "\n",
    "if not df_panels_ranked.empty:\n",
    "    plt.figure()\n",
    "    order = df_panels_ranked.sort_values(\"auroc\", ascending=False)\n",
    "    plt.bar(order[\"panel\"], order[\"auroc\"])\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"AUROC\"); plt.title(\"Per-Panel AUROC\")\n",
    "    plt.tight_layout()\n",
    "    p = str(fig_dir / \"auroc_by_panel.png\"); plt.savefig(p, dpi=200); plt.close()\n",
    "    figs[\"auroc_by_panel\"] = p\n",
    "\n",
    "    plt.figure()\n",
    "    idx = np.arange(len(df_panels_ranked))\n",
    "    vmean = pd.to_numeric(df_panels_ranked[\"vne_mean\"], errors=\"coerce\")\n",
    "    vlo = pd.to_numeric(df_panels_ranked[\"vne_lo\"], errors=\"coerce\")\n",
    "    vhi = pd.to_numeric(df_panels_ranked[\"vne_hi\"], errors=\"coerce\")\n",
    "    yerr = np.vstack([vmean - vlo, vhi - vmean]); yerr = np.nan_to_num(yerr, nan=0.0)\n",
    "    plt.errorbar(idx, vmean, yerr=yerr, fmt='o')\n",
    "    plt.xticks(idx, df_panels_ranked[\"panel\"], rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"vNE (mean ± CI)\"); plt.title(\"Per-Panel von Neumann Entropy\")\n",
    "    plt.tight_layout()\n",
    "    p = str(fig_dir / \"vne_by_panel.png\"); plt.savefig(p, dpi=200); plt.close()\n",
    "    figs[\"vne_by_panel\"] = p\n",
    "\n",
    "if not df_pairs_ranked.empty:\n",
    "    plt.figure()\n",
    "    orderp = df_pairs_ranked.sort_values(\"rank_overall\")\n",
    "    plt.bar(orderp[\"panel_pair\"], orderp[\"rank_overall\"])\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"Composite Rank (lower is better)\")\n",
    "    plt.title(\"Per-Pair Composite Rank\")\n",
    "    plt.tight_layout()\n",
    "    p = str(fig_dir / \"composite_rank_by_pair.png\"); plt.savefig(p, dpi=200); plt.close()\n",
    "    figs[\"composite_rank_by_pair\"] = p\n",
    "\n",
    "    plt.figure()\n",
    "    orderp10 = df_pairs_ranked.sort_values(\"auroc\", ascending=False).head(10)\n",
    "    plt.bar(orderp10[\"panel_pair\"], orderp10[\"auroc\"])\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"AUROC\"); plt.title(\"Top 10 Pairs by AUROC\")\n",
    "    plt.tight_layout()\n",
    "    p = str(fig_dir / \"auroc_top10_pairs.png\"); plt.savefig(p, dpi=200); plt.close()\n",
    "    figs[\"auroc_top10_pairs\"] = p\n",
    "\n",
    "    plt.figure()\n",
    "    orderp10_ece = df_pairs_ranked.sort_values(\"ece\", ascending=True).head(10)\n",
    "    plt.bar(orderp10_ece[\"panel_pair\"], orderp10_ece[\"ece\"])\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"ECE\"); plt.title(\"Top 10 Pairs by Calibration (ECE)\")\n",
    "    plt.tight_layout()\n",
    "    p = str(fig_dir / \"ece_top10_pairs.png\"); plt.savefig(p, dpi=200); plt.close()\n",
    "    figs[\"ece_top10_pairs\"] = p\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Console summary\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\nQuantum Entropy Results (vNE normalized to All_Biomarkers):\")\n",
    "for _, r in df_panels_ranked.iterrows():\n",
    "    if pd.notna(r[\"vne_norm\"]):\n",
    "        print(f\"- {r['panel']}: {r['vne_norm']:.{DEC}f}\")\n",
    "\n",
    "if \"auroc\" in df_panels_ranked.columns:\n",
    "    print(\"\\nSynergy Metrics (All_Biomarkers baseline):\")\n",
    "    try:\n",
    "        all_row = df_panels_ranked[df_panels_ranked[\"panel\"] == \"All_Biomarkers\"].iloc[0]\n",
    "        print(f\"AUC-ROC: {all_row['auroc']:.3f}\")\n",
    "    except Exception:\n",
    "        print(\"AUC-ROC: n/a\")\n",
    "\n",
    "print(\"\\n✅ Export complete\")\n",
    "print(\"Excel:\", excel_path)\n",
    "print(\"Figures:\", figs)\n",
    "print(\"Best pair (composite rank):\", best_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d75736-7cb3-4df6-91c2-4aca4c372103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 1101 samples\n",
      "Total feature columns: 177\n",
      "Numeric feature columns used: 176\n",
      "\n",
      "Dropped non-numeric columns (not used as features):\n",
      " - build\n",
      "\n",
      "=== Evaluating model: LogReg_L2 ===\n",
      " Fold 1: ROC_AUC=0.9998, F1=0.9787, Brier=0.0043\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0011\n",
      " Fold 3: ROC_AUC=0.9562, F1=0.9362, Brier=0.0108\n",
      " Fold 4: ROC_AUC=1.0000, F1=1.0000, Brier=0.0014\n",
      " Fold 5: ROC_AUC=0.9998, F1=0.9796, Brier=0.0041\n",
      "\n",
      "=== Evaluating model: LogReg_L1 ===\n",
      " Fold 1: ROC_AUC=1.0000, F1=0.9787, Brier=0.0043\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0001\n",
      " Fold 3: ROC_AUC=0.9996, F1=0.9796, Brier=0.0044\n",
      " Fold 4: ROC_AUC=1.0000, F1=0.9796, Brier=0.0016\n",
      " Fold 5: ROC_AUC=0.9998, F1=0.9583, Brier=0.0057\n",
      "\n",
      "=== Evaluating model: SVM_Linear ===\n",
      " Fold 1: ROC_AUC=0.9989, F1=0.9787, Brier=0.0049\n",
      " Fold 2: ROC_AUC=0.9989, F1=0.9787, Brier=0.0042\n",
      " Fold 3: ROC_AUC=0.9558, F1=0.9583, Brier=0.0109\n",
      " Fold 4: ROC_AUC=0.9996, F1=0.9796, Brier=0.0040\n",
      " Fold 5: ROC_AUC=0.9996, F1=0.9583, Brier=0.0068\n",
      "\n",
      "=== Evaluating model: SVM_RBF ===\n",
      " Fold 1: ROC_AUC=0.9998, F1=0.9565, Brier=0.0069\n",
      " Fold 2: ROC_AUC=0.9996, F1=0.9778, Brier=0.0046\n",
      " Fold 3: ROC_AUC=0.9962, F1=0.8636, Brier=0.0156\n",
      " Fold 4: ROC_AUC=0.9998, F1=0.9796, Brier=0.0043\n",
      " Fold 5: ROC_AUC=0.9994, F1=0.9796, Brier=0.0081\n",
      "\n",
      "=== Evaluating model: RandomForest ===\n",
      " Fold 1: ROC_AUC=1.0000, F1=0.9787, Brier=0.0028\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0018\n",
      " Fold 3: ROC_AUC=0.9996, F1=0.9796, Brier=0.0053\n",
      " Fold 4: ROC_AUC=1.0000, F1=1.0000, Brier=0.0037\n",
      " Fold 5: ROC_AUC=1.0000, F1=0.9796, Brier=0.0033\n",
      "\n",
      "=== Evaluating model: GradientBoosting ===\n",
      " Fold 1: ROC_AUC=0.9792, F1=0.9787, Brier=0.0045\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      " Fold 3: ROC_AUC=1.0000, F1=0.9796, Brier=0.0028\n",
      " Fold 4: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      " Fold 5: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      "\n",
      "=== Evaluating model: GaussianNB ===\n",
      " Fold 1: ROC_AUC=0.9907, F1=0.7692, Brier=0.0376\n",
      " Fold 2: ROC_AUC=0.8891, F1=0.5405, Brier=0.0739\n",
      " Fold 3: ROC_AUC=0.9393, F1=0.5789, Brier=0.0607\n",
      " Fold 4: ROC_AUC=0.9376, F1=0.4889, Brier=0.1029\n",
      " Fold 5: ROC_AUC=0.9601, F1=0.6275, Brier=0.0800\n",
      "\n",
      "=== Evaluating model: MLP_64_32 ===\n",
      " Fold 1: ROC_AUC=0.9979, F1=0.9583, Brier=0.0090\n",
      " Fold 2: ROC_AUC=0.9980, F1=0.9302, Brier=0.0105\n",
      " Fold 3: ROC_AUC=0.9526, F1=0.8636, Brier=0.0200\n",
      " Fold 4: ROC_AUC=0.9964, F1=0.9565, Brier=0.0129\n",
      " Fold 5: ROC_AUC=1.0000, F1=0.9787, Brier=0.0048\n",
      "\n",
      "=== Evaluating model: XGBoost ===\n",
      " Fold 1: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0001\n",
      " Fold 3: ROC_AUC=0.9994, F1=0.9796, Brier=0.0044\n",
      " Fold 4: ROC_AUC=1.0000, F1=1.0000, Brier=0.0009\n",
      " Fold 5: ROC_AUC=1.0000, F1=0.9796, Brier=0.0035\n",
      "\n",
      "=== Evaluating model: CatBoost ===\n",
      " Fold 1: ROC_AUC=1.0000, F1=0.9787, Brier=0.0044\n",
      " Fold 2: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      " Fold 3: ROC_AUC=1.0000, F1=0.9796, Brier=0.0044\n",
      " Fold 4: ROC_AUC=1.0000, F1=1.0000, Brier=0.0000\n",
      " Fold 5: ROC_AUC=1.0000, F1=1.0000, Brier=0.0009\n",
      "\n",
      "Saved model comparison metrics to: D:\\Lakshmi Kumari\\OC_Quantum_results\n",
      "\n",
      "=== Model Comparison (summary) ===\n",
      "           Model  ROC_AUC_mean  PR_AUC_mean  F1_mean  Accuracy_mean  Balanced_Accuracy_mean  Brier_mean  ECE_mean\n",
      "       LogReg_L2        0.9912       0.9875   0.9789         0.9955                  0.9865      0.0044    0.0066\n",
      "       LogReg_L1        0.9999       0.9990   0.9792         0.9955                  0.9901      0.0032    0.0055\n",
      "      SVM_Linear        0.9906       0.9822   0.9707         0.9936                  0.9855      0.0061    0.0094\n",
      "         SVM_RBF        0.9989       0.9888   0.9514         0.9900                  0.9650      0.0079    0.0164\n",
      "    RandomForest        0.9999       0.9993   0.9876         0.9973                  0.9948      0.0034    0.0213\n",
      "GradientBoosting        0.9958       0.9926   0.9917         0.9982                  0.9953      0.0015    0.0016\n",
      "      GaussianNB        0.9434       0.7056   0.6010         0.9237                  0.7500      0.0710    0.0640\n",
      "       MLP_64_32        0.9890       0.9774   0.9375         0.9873                  0.9484      0.0114    0.0255\n",
      "         XGBoost        0.9999       0.9990   0.9918         0.9982                  0.9990      0.0018    0.0041\n",
      "        CatBoost        1.0000       1.0000   0.9917         0.9982                  0.9953      0.0020    0.0024\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Automatic ML Model Benchmarking for PLCO Biomarker Data\n",
    "-------------------------------------------------------\n",
    "- Loads tabular data (e.g., PLCO biomarker panels)\n",
    "- Runs multiple ML models with 5-fold Stratified CV\n",
    "- Computes rich set of metrics:\n",
    "    * Accuracy, Balanced Accuracy\n",
    "    * Precision, Recall, Specificity, F1\n",
    "    * ROC-AUC, PR-AUC\n",
    "    * Brier Score, Log Loss\n",
    "    * MCC, Cohen's Kappa\n",
    "    * ECE (Expected Calibration Error)\n",
    "- Saves results to: model_comparison_metrics.csv\n",
    "\n",
    "You can compare these baselines against your Quantum-Inspired PLCO model.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    brier_score_loss, log_loss,\n",
    "    matthews_corrcoef, cohen_kappa_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Config: CHANGE THESE FOR YOUR DATA\n",
    "# -------------------------------------------------\n",
    "DATA_PATH = r\"D:\\Lakshmi Kumari\\merged_oc_ovars.csv\"   # your PLCO CSV\n",
    "LABEL_COL = \"is_case\"                        # binary label column (0/1)\n",
    "RANDOM_SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Utility: Expected Calibration Error (ECE)\n",
    "# -------------------------------------------------\n",
    "def compute_ece(y_true, y_prob, n_bins=10):\n",
    "    \"\"\"Expected Calibration Error (ECE) for binary classification.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    indices = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = indices == i\n",
    "        if np.sum(mask) > 0:\n",
    "            avg_pred = np.mean(y_prob[mask])\n",
    "            avg_true = np.mean(y_true[mask])\n",
    "            ece += (np.sum(mask) / len(y_prob)) * abs(avg_pred - avg_true)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Utility: Metrics for one fold\n",
    "# -------------------------------------------------\n",
    "def compute_metrics_fold(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"Compute all evaluation metrics for a single fold.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Core metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        roc = np.nan\n",
    "    try:\n",
    "        pr_auc = average_precision_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        pr_auc = np.nan\n",
    "\n",
    "    # Specificity\n",
    "    specificity = tn / (tn + fp + 1e-12)\n",
    "\n",
    "    # Calibration\n",
    "    try:\n",
    "        brier = brier_score_loss(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        brier = np.nan\n",
    "    try:\n",
    "        ll = log_loss(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        ll = np.nan\n",
    "\n",
    "    # Other\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    # ECE\n",
    "    ece = compute_ece(y_true, y_prob, n_bins=10)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Balanced_Accuracy\": bacc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1\": f1,\n",
    "        \"ROC_AUC\": roc,\n",
    "        \"PR_AUC\": pr_auc,\n",
    "        \"Brier\": brier,\n",
    "        \"LogLoss\": ll,\n",
    "        \"MCC\": mcc,\n",
    "        \"Kappa\": kappa,\n",
    "        \"ECE\": ece,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"TN\": tn,\n",
    "        \"FN\": fn,\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Define Models\n",
    "# -------------------------------------------------\n",
    "def get_models():\n",
    "    \"\"\"\n",
    "    Returns a dict of model_name -> (estimator, needs_scaling_flag)\n",
    "    All will be wrapped in Pipeline with Imputer (+ optional Scaler).\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # Logistic Regression (L2)\n",
    "    models[\"LogReg_L2\"] = (\n",
    "        LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=500,\n",
    "            class_weight=None,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "\n",
    "    # Logistic Regression (L1)\n",
    "    models[\"LogReg_L1\"] = (\n",
    "        LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=500,\n",
    "            class_weight=None,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "\n",
    "    # Linear SVM\n",
    "    models[\"SVM_Linear\"] = (\n",
    "        SVC(\n",
    "            kernel=\"linear\",\n",
    "            probability=True,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "\n",
    "    # RBF SVM\n",
    "    models[\"SVM_RBF\"] = (\n",
    "        SVC(\n",
    "            kernel=\"rbf\",\n",
    "            probability=True,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "\n",
    "    # Random Forest\n",
    "    models[\"RandomForest\"] = (\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            random_state=RANDOM_SEED,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        False\n",
    "    )\n",
    "\n",
    "    # Gradient Boosting\n",
    "    models[\"GradientBoosting\"] = (\n",
    "        GradientBoostingClassifier(\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        False\n",
    "    )\n",
    "\n",
    "    # Naive Bayes\n",
    "    models[\"GaussianNB\"] = (\n",
    "        GaussianNB(),\n",
    "        False  # scaling is not required\n",
    "    )\n",
    "\n",
    "    # MLP (simple)\n",
    "    models[\"MLP_64_32\"] = (\n",
    "        MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=1e-3,\n",
    "            learning_rate_init=1e-3,\n",
    "            max_iter=500,\n",
    "            early_stopping=True,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "\n",
    "    # Optionally add XGBoost / LightGBM / CatBoost if installed\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        models[\"XGBoost\"] = (\n",
    "            XGBClassifier(\n",
    "                n_estimators=400,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=4,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                eval_metric=\"logloss\",\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            False\n",
    "        )\n",
    "    except ImportError:\n",
    "        print(\"XGBoost not installed; skipping XGBoost model.\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        from catboost import CatBoostClassifier\n",
    "        models[\"CatBoost\"] = (\n",
    "            CatBoostClassifier(\n",
    "                iterations=400,\n",
    "                learning_rate=0.05,\n",
    "                depth=4,\n",
    "                verbose=False,\n",
    "                random_state=RANDOM_SEED\n",
    "            ),\n",
    "            False\n",
    "        )\n",
    "    except ImportError:\n",
    "        print(\"CatBoost not installed; skipping CatBoost model.\")\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Main CV Evaluation\n",
    "# -------------------------------------------------\n",
    "def evaluate_models_cv(X, y, n_splits=5, random_state=7):\n",
    "    models = get_models()\n",
    "    results = []\n",
    "\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    for model_name, (base_clf, need_scaling) in models.items():\n",
    "        print(f\"\\n=== Evaluating model: {model_name} ===\")\n",
    "\n",
    "        # Build pipeline\n",
    "        steps = [(\"imp\", SimpleImputer(strategy=\"median\"))]\n",
    "        if need_scaling:\n",
    "            steps.append((\"sc\", StandardScaler()))\n",
    "        steps.append((\"clf\", base_clf))\n",
    "        pipe = Pipeline(steps)\n",
    "\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X, y), start=1):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            pipe.fit(X_train, y_train)\n",
    "            # predicted probabilities for positive class\n",
    "            y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            m = compute_metrics_fold(y_test, y_prob, threshold=0.5)\n",
    "            fold_metrics.append(m)\n",
    "            print(f\" Fold {fold_idx}: ROC_AUC={m['ROC_AUC']:.4f}, F1={m['F1']:.4f}, Brier={m['Brier']:.4f}\")\n",
    "\n",
    "        # Aggregate metrics over folds (mean & std)\n",
    "        metrics_df = pd.DataFrame(fold_metrics)\n",
    "        mean_metrics = metrics_df.mean()\n",
    "        std_metrics = metrics_df.std()\n",
    "\n",
    "        row = {\"Model\": model_name}\n",
    "        for metric_name in mean_metrics.index:\n",
    "            row[f\"{metric_name}_mean\"] = mean_metrics[metric_name]\n",
    "            row[f\"{metric_name}_std\"] = std_metrics[metric_name]\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Run Everything\n",
    "# -------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    assert LABEL_COL in df.columns, f\"Label column '{LABEL_COL}' not found.\"\n",
    "\n",
    "    # ======== FIXED FEATURE SELECTION HERE ========\n",
    "    feature_df = df.drop(columns=[LABEL_COL])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    X = feature_df[numeric_cols].to_numpy()\n",
    "    y = df[LABEL_COL].astype(int).to_numpy()\n",
    "\n",
    "    print(f\"Loaded data: {df.shape[0]} samples\")\n",
    "    print(f\"Total feature columns: {feature_df.shape[1]}\")\n",
    "    print(f\"Numeric feature columns used: {len(numeric_cols)}\")\n",
    "\n",
    "    dropped_cols = sorted(set(feature_df.columns) - set(numeric_cols))\n",
    "    if dropped_cols:\n",
    "        print(\"\\nDropped non-numeric columns (not used as features):\")\n",
    "        for c in dropped_cols:\n",
    "            print(\" -\", c)\n",
    "    # =============================================\n",
    "\n",
    "    results_df = evaluate_models_cv(X, y, n_splits=N_SPLITS, random_state=RANDOM_SEED)\n",
    "\n",
    "    out_path = r\"D:\\Lakshmi Kumari\\OC_Quantum_results\"\n",
    "    results_df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(\"\\nSaved model comparison metrics to:\", out_path)\n",
    "    print(\"\\n=== Model Comparison (summary) ===\")\n",
    "    print(results_df[[\"Model\", \"ROC_AUC_mean\", \"PR_AUC_mean\", \"F1_mean\",\n",
    "                      \"Accuracy_mean\", \"Balanced_Accuracy_mean\",\n",
    "                      \"Brier_mean\", \"ECE_mean\"]].round(4).to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203fe6db-869d-4acd-92ab-30dce57d57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "AUC=1.0000, PR-AUC=1.0000, F1=0.0000, Brier=0.1084, ECE=0.1085\n",
      "\n",
      "=== Fold 2 ===\n",
      "AUC=0.9925, PR-AUC=0.9495, F1=0.0000, Brier=0.1045, ECE=0.1045\n",
      "\n",
      "=== Fold 3 ===\n",
      "AUC=0.9998, PR-AUC=0.9983, F1=0.1967, Brier=0.8909, ECE=0.8909\n",
      "\n",
      "=== Fold 4 ===\n",
      "AUC=0.9994, PR-AUC=0.9948, F1=0.0000, Brier=0.0763, ECE=0.0901\n",
      "\n",
      "=== Fold 5 ===\n",
      "AUC=1.0000, PR-AUC=1.0000, F1=0.0000, Brier=0.1090, ECE=0.1091\n",
      "\n",
      "=== Quantum-Entropy Model Summary ===\n",
      "    Metric      Mean       Std\n",
      "0  ROC_AUC  0.998329  0.002926\n",
      "1   PR_AUC  0.988521  0.019611\n",
      "2       F1  0.039344  0.078689\n",
      "3    Brier  0.257839  0.316766\n",
      "4      ECE  0.260615  0.315222\n",
      "\n",
      "Saved QE model results → quantum_entropy_plco_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Quantum-Entropy PLCO Model (Clean Baseline Comparison)\n",
    "# ================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Quantum-Entropy Feature Modulation\n",
    "# ---------------------------------------------------------\n",
    "def quantum_entropy_modulation(X):\n",
    "    \"\"\"\n",
    "    Computes per-feature Tsallis entropy and rescales features.\n",
    "    \"\"\"\n",
    "    mod_X = np.zeros_like(X)\n",
    "    for j in range(X.shape[1]):\n",
    "        col = X[:, j]\n",
    "        col = np.nan_to_num(col, nan=np.nanmedian(col))\n",
    "        # Tsallis entropy (q=1.2)\n",
    "        hist, _ = np.histogram(col, bins=30, density=True)\n",
    "        hist = hist + 1e-10\n",
    "        S = (1 - np.sum(hist ** 1.2)) / 0.2\n",
    "        mod_X[:, j] = col * (1 + S)  # entropy-modulated feature\n",
    "    return mod_X\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# QE Model: logistic baseline + entropy modulation + calibration\n",
    "# ---------------------------------------------------------\n",
    "class QuantumEntropyCLF(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.base = LogisticRegression(penalty=\"l2\", max_iter=5000)\n",
    "        self.calib = CalibratedClassifierCV(self.base, cv=\"prefit\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xq = quantum_entropy_modulation(X)\n",
    "        Xs = self.scaler.fit_transform(Xq)\n",
    "        self.base.fit(Xs, y)\n",
    "        self.calib = CalibratedClassifierCV(self.base, cv=3)\n",
    "        self.calib.fit(Xs, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        Xq = quantum_entropy_modulation(X)\n",
    "        Xs = self.scaler.transform(Xq)\n",
    "        return self.calib.predict_proba(Xs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:,1] >= 0.5).astype(int)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Metrics\n",
    "# ---------------------------------------------------------\n",
    "def ece_score(y_true, y_prob, bins=10):\n",
    "    bins_edges = np.linspace(0, 1, bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(bins):\n",
    "        start, end = bins_edges[i], bins_edges[i+1]\n",
    "        mask = (y_prob >= start) & (y_prob < end)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        acc = y_true[mask].mean()\n",
    "        conf = y_prob[mask].mean()\n",
    "        ece += abs(acc - conf) * mask.mean()\n",
    "    return ece\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Cross-Validation\n",
    "# ---------------------------------------------------------\n",
    "results = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    fold += 1\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = QuantumEntropyCLF()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    prob = model.predict_proba(X_test)[:,1]\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y_test, prob)\n",
    "    pr  = average_precision_score(y_test, prob)\n",
    "    f1  = f1_score(y_test, pred)\n",
    "    brier = np.mean((prob - y_test)**2)\n",
    "    ece  = ece_score(y_test, prob)\n",
    "\n",
    "    print(f\"AUC={roc:.4f}, PR-AUC={pr:.4f}, F1={f1:.4f}, Brier={brier:.4f}, ECE={ece:.4f}\")\n",
    "\n",
    "    results.append([roc, pr, f1, brier, ece])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Summary\n",
    "# ---------------------------------------------------------\n",
    "results = np.array(results)\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\"ROC_AUC\", \"PR_AUC\", \"F1\", \"Brier\", \"ECE\"],\n",
    "    \"Mean\": results.mean(axis=0),\n",
    "    \"Std\": results.std(axis=0)\n",
    "})\n",
    "\n",
    "print(\"\\n=== Quantum-Entropy Model Summary ===\")\n",
    "print(summary)\n",
    "\n",
    "summary.to_csv(\"quantum_entropy_plco_results.csv\", index=False)\n",
    "print(\"\\nSaved QE model results → quantum_entropy_plco_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfeeb1-5173-4657-963d-a770580b0af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
